{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12136a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eeaf470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100]\n",
      "(1, 100)\n",
      "[[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "   19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "   37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "   55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "   73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "   91  92  93  94  95  96  97  98  99 100]]\n",
      "(100, 1)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,101)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "b = a.reshape(1,-1)#-1是指系統自己計算\n",
    "print(b.shape)\n",
    "print(b)\n",
    "\n",
    "X = np.arange(1,101).reshape(-1,1)\n",
    "y = np.arange(101,201)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9ae490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 1)\n",
      "(30, 1)\n",
      "(70,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "#切割資料集(訓練70% + 測試30%)\n",
    "X_train, X_temp, y_train, y_temp  = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_temp.shape)\n",
    "print(y_train.shape)\n",
    "print(y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8288e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 1)\n",
      "(15, 1)\n",
      "(15,)\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "#切割資料集(驗證15% + 測試15%)\n",
    "X_val, X_test, y_val, y_test  = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80a5506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2) (50, 2) (150,) (50,) (30, 2) (20, 2) (30,) (20,)\n",
      "[[229 230]\n",
      " [347 348]\n",
      " [ 11  12]]\n",
      "[[191 192]\n",
      " [ 31  32]\n",
      " [ 61  62]]\n",
      "[615 674 506]\n",
      "[596 516 531]\n",
      "[[ 91  92]\n",
      " [113 114]\n",
      " [131 132]]\n",
      "[[157 158]\n",
      " [153 154]\n",
      " [ 19  20]]\n",
      "[546 557 566]\n",
      "[579 577 510]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,401).reshape(-1,2)\n",
    "y = np.arange(501,701)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp  = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_val, X_test, y_val, y_test  = train_test_split(X_temp, y_temp, test_size=0.4, random_state=42)\n",
    "print(X_train.shape, X_temp.shape, y_train.shape, y_temp.shape, X_val.shape, X_test.shape, y_val.shape, y_test.shape)\n",
    "print(X_train[:3])\n",
    "print(X_temp[:3])\n",
    "print(y_train[:3])\n",
    "print(y_temp[:3])\n",
    "print(X_val[:3])\n",
    "print(X_test[:3])\n",
    "print(y_val[:3])\n",
    "print(y_test[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577b614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "[ 0.07562188  6.95612449  2.65246238 14.75803882 10.84447411]\n"
     ]
    }
   ],
   "source": [
    "#交叉驗證(k-fold)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split , KFold , cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[i] for i in range(1,101)])\n",
    "y = np.array([2*i + np.random.randn()*5 for i in range(1,101)])\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c74a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-30.09652633 -23.39237987]\n",
      "每個fold的MSE:[30.09652633 23.39237987]\n",
      "mean_mse:26.74\n",
      "std_mse:3.35\n"
     ]
    }
   ],
   "source": [
    "#線性回歸\n",
    "model = LinearRegression()\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)#n_splits劃分群數 shuffle是否打亂資料\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "print(scores)\n",
    "print(f\"每個fold的MSE:{np.abs(scores)}\")\n",
    "mean_mse = np.abs(scores).mean()\n",
    "std_mse = np.abs(scores).std()\n",
    "print(f\"mean_mse:{mean_mse:.2f}\")\n",
    "print(f\"std_mse:{std_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d512e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1個fold:訓練樣本數:50, 測試樣本數:50, MSE=30.10\n",
      "第2個fold:訓練樣本數:50, 測試樣本數:50, MSE=23.39\n"
     ]
    }
   ],
   "source": [
    "#細部解說\n",
    "fold_idx = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index] , X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #模型訓練\n",
    "    model.fit(X_train,y_train)\n",
    "    #預測結果\n",
    "    y_pred = model.predict(X_test)\n",
    "    #計算誤差\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    current_mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"第{fold_idx}個fold:訓練樣本數:{len(X_train)}, 測試樣本數:{len(X_test)}, MSE={current_mse:.2f}\")\n",
    "    fold_idx+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb2779d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10)\n",
      "(300,)\n",
      "mean_accuracy: 0.923\n",
      "std_accuracy: 3.352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X,y = make_classification(n_samples=300, n_features=10, n_classes=2, random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "model = LogisticRegression(random_state = 42, solver = 'liblinear')\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "socres = cross_val_score(model,X , y, cv=kf, scoring='accuracy')\n",
    "mean_accuracy = socres.mean()\n",
    "std_accuracy = scores.std()\n",
    "print(f\"mean_accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"std_accuracy: {std_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa776181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: [0.01, 0.1, 1, 10, 100]\n",
      "penalty: ['l1', 'l2']\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "best_parms : {'C': 0.1, 'penalty': 'l1'}\n",
      "best_score: 0.933\n",
      "best_model: LogisticRegression(C=0.1, penalty='l1', random_state=42, solver='liblinear')\n",
      "   param_C param_penalty  mean_test_score  std_test_score\n",
      "3     0.10            l2         0.933333        0.018257\n",
      "2     0.10            l1         0.933333        0.025820\n",
      "0     0.01            l1         0.930000        0.024495\n",
      "4     1.00            l1         0.926667        0.027080\n",
      "5     1.00            l2         0.923333        0.034319\n",
      "1     0.01            l2         0.920000        0.026667\n",
      "6    10.00            l1         0.913333        0.046428\n",
      "7    10.00            l2         0.913333        0.046428\n",
      "8   100.00            l1         0.913333        0.046428\n",
      "9   100.00            l2         0.913333        0.046428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, y = make_classification(n_samples=300, n_features=20, n_classes=2, random_state=42)\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "param_grid = {\n",
    "    'C':[0.01,0.1,1,10,100],\n",
    "    'penalty':['l1','l2']\n",
    "}\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"{param}: {values}\")\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', verbose=1, n_jobs=-1, cv=5)\n",
    "grid_search.fit(X,y)\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"best_parms : {best_params}\")\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"best_score: {best_score:.3f}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"best_model: {best_model}\")\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results_df[['param_C','param_penalty','mean_test_score','std_test_score']].sort_values(by = 'mean_test_score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b398e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: [3, 5, 7, None]\n",
      "min_samples_split: [2, 5, 10]\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "best_parms : {'max_depth': 3, 'min_samples_split': 2}\n",
      "best_score: 0.856\n",
      "best_model: DecisionTreeClassifier(max_depth=3, random_state=42)\n",
      "   param_max_depth  param_min_samples_split  mean_test_score  std_test_score\n",
      "0                3                        2         0.855863        0.036310\n",
      "1                3                        5         0.855863        0.036310\n",
      "2                3                       10         0.851895        0.038490\n",
      "11            None                       10         0.827829        0.063886\n",
      "8                7                       10         0.827829        0.063886\n",
      "7                7                        5         0.827765        0.068050\n",
      "10            None                        5         0.827765        0.068050\n",
      "5                5                       10         0.823797        0.061500\n",
      "4                5                        5         0.823733        0.065812\n",
      "6                7                        2         0.815796        0.062160\n",
      "9             None                        2         0.815796        0.062160\n",
      "3                5                        2         0.815732        0.059171\n"
     ]
    }
   ],
   "source": [
    "#test1\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_ex1, y_ex1 = make_classification(n_samples=250, n_features=20, n_classes=2, random_state=42)\n",
    "model_ex1 = DecisionTreeClassifier(random_state=42)\n",
    "param_grid_ex1 = {\n",
    "    'max_depth':[3,5,7,None],\n",
    "    'min_samples_split':[2,5,10]\n",
    "}\n",
    "for param, values in param_grid_ex1.items():\n",
    "    print(f\"{param}: {values}\")\n",
    "grid_search_ex1 = GridSearchCV(estimator=model_ex1, param_grid=param_grid_ex1, scoring='accuracy', verbose=1, n_jobs=-1, cv=4)\n",
    "grid_search_ex1.fit(X_ex1, y_ex1)\n",
    "best_params = grid_search_ex1.best_params_\n",
    "print(f\"best_parms : {best_params}\")\n",
    "best_score = grid_search_ex1.best_score_\n",
    "print(f\"best_score: {best_score:.3f}\")\n",
    "best_model = grid_search_ex1.best_estimator_\n",
    "print(f\"best_model: {best_model}\")\n",
    "\n",
    "results_df = pd.DataFrame(grid_search_ex1.cv_results_)\n",
    "\n",
    "print(results_df[['param_max_depth','param_min_samples_split','mean_test_score','std_test_score']].sort_values(by = 'mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "195cd173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
      "penalty: ['l2']\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "best_parms : {'C': 0.001, 'penalty': 'l2'}\n",
      "best_score: 0.832\n",
      "best_model: LogisticRegression(C=0.001, random_state=7, solver='liblinear')\n",
      "    param_C param_penalty  mean_test_score  std_test_score\n",
      "0     0.001            l2            0.832        0.044900\n",
      "1     0.010            l2            0.816        0.055714\n",
      "2     0.100            l2            0.800        0.060663\n",
      "4    10.000            l2            0.800        0.075895\n",
      "5   100.000            l2            0.800        0.075895\n",
      "6  1000.000            l2            0.800        0.075895\n",
      "3     1.000            l2            0.792        0.078588\n"
     ]
    }
   ],
   "source": [
    "#test2\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_ex2, y_ex2 = make_classification(n_samples=250, n_features=20, n_classes=2, random_state=7)\n",
    "model_ex2 = LogisticRegression(penalty='12',random_state=7, solver='liblinear')\n",
    "param_grid_ex2 = {\n",
    "    'C':[0.001,0.01,0.1,1,10,100,1000],\n",
    "    'penalty':['l2']\n",
    "}\n",
    "for param, values in param_grid_ex2.items():\n",
    "    print(f\"{param}: {values}\")\n",
    "grid_search_ex2 = GridSearchCV(estimator=model_ex2, param_grid=param_grid_ex2, scoring='accuracy', verbose=1, n_jobs=-1, cv=5)\n",
    "grid_search_ex2.fit(X_ex2,y_ex2)\n",
    "best_params = grid_search_ex2.best_params_\n",
    "print(f\"best_parms : {best_params}\")\n",
    "best_score = grid_search_ex2.best_score_\n",
    "print(f\"best_score: {best_score:.3f}\")\n",
    "best_model = grid_search_ex2.best_estimator_\n",
    "print(f\"best_model: {best_model}\")\n",
    "\n",
    "results_df = pd.DataFrame(grid_search_ex2.cv_results_)\n",
    "print(results_df[['param_C','param_penalty','mean_test_score','std_test_score']].sort_values(by = 'mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0719a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_rf: 0.813\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84        78\n",
      "           1       0.89      0.69      0.78        72\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.83      0.81      0.81       150\n",
      "weighted avg       0.83      0.81      0.81       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#隨機樹\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=100, n_classes = 2 , random_state=7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "rf_classfiier = RandomForestClassifier(n_estimators=100, random_state=7, n_jobs=-1, max_features='sqrt')#n_estimators決策樹的數量 越多越好 吃效能\n",
    "rf_classfiier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classfiier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"accuracy_rf: {accuracy_rf:.3f}\")\n",
    "print(f\"classification_report: {classification_report(y_test,y_pred_rf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70f6df9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importances = rf_classfiier.feature_importances_\n",
    "plt.bar(range(len(importances)),importances)\n",
    "plt.title(\"Feature Importances (RF_Classifier)\")\n",
    "plt.xticks(ticks=range(len(importances)), labels=range(1, len(importances)+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0663474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "best_params:{'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "avg_accuracy:0.921\n",
      "測試資料在最佳模型的正確率:0.911\n"
     ]
    }
   ],
   "source": [
    "#隨機樹test1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, y = make_classification(n_samples=600, n_features=15, n_classes = 2 , random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_classfiier = RandomForestClassifier(random_state=7, n_jobs=-1)#n_estimators決策樹的數量 越多越好 吃效能\n",
    "param_grid_rf = {\n",
    "    'n_estimators':[50,100,200],\n",
    "    'max_depth':[5,10,None],\n",
    "    'max_features':['sqrt',0.5,1.0]\n",
    "}\n",
    "#GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classfiier, param_grid=param_grid_rf,cv=3, scoring='accuracy', n_jobs=-1 , verbose=1)\n",
    "grid_search_rf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(f\"best_params:{grid_search_rf.best_params_}\")\n",
    "print(f\"avg_accuracy:{grid_search_rf.best_score_:.3f}\")\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"測試資料在最佳模型的正確率:{test_accuracy_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002217d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_ex2: 9644.753\n",
      "r2_ex2: 0.667\n",
      "       Feature  Importance\n",
      "6    Feature_6    0.410451\n",
      "3    Feature_3    0.163247\n",
      "9    Feature_9    0.156310\n",
      "2    Feature_2    0.057581\n",
      "10  Feature_10    0.040806\n",
      "8    Feature_8    0.039076\n",
      "5    Feature_5    0.030123\n",
      "4    Feature_4    0.028397\n",
      "7    Feature_7    0.020714\n",
      "1    Feature_1    0.018214\n",
      "0    Feature_0    0.018079\n",
      "11  Feature_11    0.017001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# 產生資料\n",
    "X_ex2, y_ex2 = make_regression(n_samples=400, n_features=12, noise=30, random_state=42)\n",
    "\n",
    "# 切分資料\n",
    "X_train_ex2, X_test_ex2, y_train_ex2, y_test_ex2 = train_test_split(\n",
    "    X_ex2, y_ex2, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# 建立並訓練模型\n",
    "rfr_model = RandomForestRegressor(n_estimators=150, random_state=42, n_jobs=-1)\n",
    "rfr_model.fit(X_train_ex2, y_train_ex2)\n",
    "\n",
    "# 預測\n",
    "y_pred_rfr = rfr_model.predict(X_test_ex2)\n",
    "\n",
    "# 評估\n",
    "mse_ex2 = mean_squared_error(y_test_ex2, y_pred_rfr)\n",
    "r2_ex2 = r2_score(y_test_ex2, y_pred_rfr)\n",
    "\n",
    "print(f'mse_ex2: {mse_ex2:.3f}')\n",
    "print(f'r2_ex2: {r2_ex2:.3f}')\n",
    "\n",
    "# 特徵重要性\n",
    "feature_importances = rfr_model.feature_importances_\n",
    "feature_names = [f'Feature_{i}' for i in range(X_ex2.shape[1])]\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dfbe193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        68\n",
      "           1       0.99      0.89      0.94        82\n",
      "\n",
      "    accuracy                           0.93       150\n",
      "   macro avg       0.93      0.94      0.93       150\n",
      "weighted avg       0.94      0.93      0.93       150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI-NB\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:23:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"object\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "X, y = make_classification(n_samples=500, n_features=20, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.3, random_state=42)\n",
    "xgb_classifier = XGBClassifier(object='binary:logistic', n_estimators=100, learning_rate=0.1, eval_metric='logloss', random_state=42)\n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"accuracy: {accuracy:.3f}\")\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor   # 匯入 XGBoost 模型\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 產生資料\n",
    "X_reg, y_reg = make_regression(n_samples=500, n_features=10, noise=30, random_state=42)\n",
    "# 切分資料\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "# 建立 XGBoost 回歸模型\n",
    "xgb_regressor = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "xgb_regressor.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# 預測\n",
    "y_pred_reg = xgb_regressor.predict(X_test_reg)\n",
    "\n",
    "# 評估指標\n",
    "mse_reg = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mape_reg = mean_absolute_percentage_error(y_test_reg, y_pred_reg)\n",
    "r2_reg = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f'mse_reg: {mse_reg:.3f}')\n",
    "print(f'mape_reg: {mape_reg:.3f}')\n",
    "print(f'r2_reg: {r2_reg:.3f}')\n",
    "\n",
    "# 特徵重要性\n",
    "feature_importances_reg = xgb_regressor.feature_importances_\n",
    "feature_names_reg = [f'Feature_{i}' for i in range(X_reg.shape[1])]\n",
    "\n",
    "importance_df_rgb = pd.DataFrame({\n",
    "    'Feature': feature_names_reg,\n",
    "    'Importance': feature_importances_reg\n",
    "})\n",
    "\n",
    "importance_df_rgb = importance_df_rgb.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df_rgb)\n",
    "\n",
    "# 繪圖\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df_rgb['Feature'], importance_df_rgb['Importance'])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost Regressor Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # 讓最重要的排在上面\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
